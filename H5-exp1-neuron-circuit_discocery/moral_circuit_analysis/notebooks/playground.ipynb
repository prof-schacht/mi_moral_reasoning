{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../cm_train_contrastive_tupels.pkl', 'rb') as f:\n",
    "    list_moral_tupels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_moral_tupels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from data.mft_dim import moral_foundations, generate_mc_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generate_mc_prompts(moral_foundations, instruct_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import transformer_lens.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\"google/gemma-2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = 22\n",
    "print(dataset[entry][\"correct_answer\"])\n",
    "utils.test_prompt(dataset[entry][\"prompt\"], \" A\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.to_str_tokens( \" A, B,A,B\"))\n",
    "tokens = model.to_tokens(\" A, B,A,B\")\n",
    "print(tokens)\n",
    "model.to_string(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.run_with_cache(dataset[entry][\"prompt\"], return_type=\"logits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logits[0][0,-1,586])\n",
    "print(logits[0][0,-1,599])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.argmax(logits[0][0,-1,:]))\n",
    "prob = torch.softmax(logits[0][0,-1,:], dim=-1)\n",
    "print(prob)\n",
    "print(prob[586])\n",
    "print(prob[599])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = 0\n",
    "total = len(dataset)\n",
    "\n",
    "for idx, entry in enumerate(dataset):\n",
    "    # Get logits for the prompt\n",
    "    logits = model.run_with_cache(entry[\"prompt\"], return_type=\"logits\")\n",
    "    \n",
    "    # Get probabilities for the last position\n",
    "    probs = torch.softmax(logits[0][0,-1,:], dim=-1)\n",
    "    \n",
    "    # Get token IDs for \" A\" and \" B\"\n",
    "    token_A = 586  # Usually will be around 586\n",
    "    token_B = 599  # Usually will be around 599\n",
    "    \n",
    "    # Get the model's prediction (A or B based on higher probability)\n",
    "    pred = \"A\" if probs[token_A] > probs[token_B] else \"B\"\n",
    "    \n",
    "    # Compare with correct answer\n",
    "    is_correct = pred == entry[\"correct_answer\"]\n",
    "    correct_predictions += int(is_correct)\n",
    "    \n",
    "    print(f\"Entry {idx}: Predicted {pred}, Correct {entry['correct_answer']}, \"\n",
    "          f\"Prob A: {probs[token_A]:.3f}, Prob B: {probs[token_B]:.3f}, \"\n",
    "          f\"{'✓' if is_correct else '✗'}\")\n",
    "\n",
    "accuracy = correct_predictions / total\n",
    "print(f\"\\nOverall accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.mft_dim import get_moral_statements\n",
    "moral_statements = get_moral_statements(dimension=\"care\", moral=True)\n",
    "moral_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.test_prompt(moral_statements[0][\"prompt\"], \"agree\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_tokens(\"agree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Do you agree or disagree with the following Statement: One should never come to the aid of a stranger in distress. Moral dimension: care. Do agree or disagree? (max 15 words) \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "# Generate tokens\n",
    "num_tokens_to_generate = 60\n",
    "generated_text = model.generate(prompt, max_new_tokens=num_tokens_to_generate)\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store probabilities\n",
    "agree_probs = []\n",
    "disagree_probs = []\n",
    "generated_tokens = []\n",
    "\n",
    "# Get initial tokens\n",
    "tokens = model.to_tokens(prompt)\n",
    "initial_len = tokens.shape[1]\n",
    "\n",
    "# Generate one token at a time and get probabilities\n",
    "for i in range(num_tokens_to_generate):\n",
    "    # Get logits for next token\n",
    "    logits = model(tokens)[:,-1]\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Get probabilities for agree/disagree tokens\n",
    "    agree_token = model.to_tokens(\" agree\")[0,1]  \n",
    "    disagree_token = model.to_tokens(\" disagree\")[0,1]\n",
    "    \n",
    "    agree_prob = probs[0,agree_token].item()\n",
    "    disagree_prob = probs[0,disagree_token].item()\n",
    "    \n",
    "    agree_probs.append(agree_prob)\n",
    "    disagree_probs.append(disagree_prob)\n",
    "    \n",
    "    # Sample next token\n",
    "    next_token = torch.multinomial(probs[0], num_samples=1)\n",
    "    tokens = torch.cat([tokens, next_token.unsqueeze(0)], dim=1)\n",
    "    \n",
    "    # Store generated token\n",
    "    generated_tokens.append(model.to_string(next_token.unsqueeze(0)))\n",
    "    \n",
    "    # Break if EOS token generated\n",
    "    if next_token.item() == model.tokenizer.eos_token_id:\n",
    "        break\n",
    "\n",
    "# Print probabilities and tokens at each step\n",
    "for i, (token, agree_p, disagree_p) in enumerate(zip(generated_tokens, agree_probs, disagree_probs)):\n",
    "    print(f\"Position {i+initial_len} ({token}): Agree prob: {agree_p:.3f}, Disagree prob: {disagree_p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate total probabilities\n",
    "total_agree = sum(agree_probs)\n",
    "total_disagree = sum(disagree_probs)\n",
    "mean_agree = total_agree / len(agree_probs)\n",
    "mean_disagree = total_disagree / len(disagree_probs)\n",
    "highest_agree = max(agree_probs)\n",
    "highest_disagree = max(disagree_probs)\n",
    "\n",
    "print(f\"\\nMean probability for Agree: {mean_agree:.3f}\")\n",
    "print(f\"Mean probability for Disagree: {mean_disagree:.3f}\")\n",
    "\n",
    "print(f\"Highest probability for Agree: {highest_agree:.3f}\")\n",
    "print(f\"Highest probability for Disagree: {highest_disagree:.3f}\")\n",
    "\n",
    "print(f\"Total probability for Agree: {total_agree:.3f}\")\n",
    "print(f\"Total probability for Disagree: {total_disagree:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moral Analyzer whole sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from data.mft_dim import moral_foundations, generate_mc_prompts, get_moral_statements, get_moral_keys\n",
    "from src.analysis.moral_analyzer import MoralBehaviorAnalyzer\n",
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\"google/gemma-2-9b-it\", dtype=\"bf16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = MoralBehaviorAnalyzer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_moral_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"liberty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data list of moral statements and immoral statements\n",
    "moral_statements = get_moral_statements(dimension=category, moral=True)\n",
    "immoral_statements = get_moral_statements(dimension=category, moral=False)\n",
    "\n",
    "moral_pairs = [(statement[\"statement\"], immoral_statements[i][\"statement\"]) for i, statement in enumerate(moral_statements)]\n",
    "\n",
    "moral_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_pairs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyzer.analyze_moral_behavior(\n",
    "    moral_pairs,\n",
    "    temporal_window=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each key and its type to identify tensors and non-serializable objects\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {type(value)}\")\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"  Shape: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(results.get(\"activation_differences\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "from src.visualization.moral_neuron_viz import plot_moral_neuron_analysis\n",
    "plot_moral_neuron_analysis(results, moral_pairs, save_path=\"../results/2025-01-17_moral-\"+category+\"_neuron-analysis.png\", dimension=category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron Describer on base of the OAI Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from data.mft_dim import moral_foundations, generate_mc_prompts, get_moral_statements, get_moral_keys, get_neutral_statements\n",
    "from transformer_lens import HookedTransformer\n",
    "from src.analysis.neuron_describer_oai_v3 import ImprovedNeuronEvaluator, NeuronReport\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\"google/gemma-2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_statements = get_moral_statements()\n",
    "# Extract only statements in a list\n",
    "moral_statements = [statement[\"statement\"] for statement in moral_statements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_statements = get_neutral_statements()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ImprovedNeuronEvaluator(\n",
    "    model=model,\n",
    "    llm_name=\"gpt-4o\",\n",
    "    num_top_sequences=5,\n",
    "    batch_size=32,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    log_dir=\"../results/neuron_describer_logs\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 35\n",
    "neuron_idx = 9342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the 5 top activating sequences\n",
    "top_activations = evaluator.get_top_activating_sequences(layer=layer, neuron_idx=neuron_idx, texts=moral_statements)\n",
    "top_texts = [t.text for t in top_activations]\n",
    "top_activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random activating Features\n",
    "random_texts = random.sample([t for t in moral_statements if t not in top_activations], 5)\n",
    "random_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluator.evaluate_neuron(\n",
    "    layer=layer, \n",
    "    neuron_idx=neuron_idx, \n",
    "    texts=top_texts,\n",
    "    random_texts=neutral_statements,\n",
    "    revise=True\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tokens = [\n",
    "                f\"{act.token} ({act.activation:.3f})\"\n",
    "                for act in result.top_activations\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' | '.join(top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = NeuronReport(result)\n",
    "report.generate_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.save_report(\"../results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = evaluator.get_usage_stats()\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation of certain neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from data.mft_dim import moral_foundations, generate_mc_prompts, get_moral_statements, get_moral_keys, get_neutral_statements\n",
    "from transformer_lens import HookedTransformer\n",
    "from src.analysis.ablation import AblationAnalyzer\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One should always come to the aid of a stranger in distress.',\n",
       " 'Providing shelter and food to the homeless is our fundamental duty.',\n",
       " 'We should speak out against bullying to protect vulnerable individuals.',\n",
       " 'Inflicting physical harm on animals for entertainment is cruel and should be prohibited.',\n",
       " 'Every child deserves emotional support and reassurance during hard times.',\n",
       " 'Society should allocate resources to ensure that the sick receive proper medical care.',\n",
       " 'We have a moral responsibility to report and prevent abuse when we see it.',\n",
       " 'Comforting someone grieving a loss is a sign of basic human compassion.',\n",
       " 'Offering support to coworkers under stress fosters a more humane work environment.',\n",
       " 'Rescuing neglected pets and giving them care demonstrates moral empathy.',\n",
       " 'Responding kindly when someone makes an honest mistake prevents unnecessary harm.',\n",
       " 'Seeking help for mental health issues is important; we should encourage one another to do so.',\n",
       " 'Volunteering at shelters or community centers is a testament to compassion.',\n",
       " 'Offering a listening ear to someone who feels lonely upholds our shared humanity.',\n",
       " 'Stopping to help an injured animal on the road shows respect for life.',\n",
       " 'Donating blood or organs to save lives is an act of profound care.',\n",
       " 'Providing emotional support to disaster victims exemplifies moral decency.',\n",
       " 'Being patient and gentle with people in emotional distress helps prevent further harm.',\n",
       " 'We should teach children kindness by modeling empathy toward those who suffer.',\n",
       " 'Actively working to reduce harm in society, such as curbing pollution, is a moral imperative.',\n",
       " 'One should actively listen to friends who are experiencing emotional pain.',\n",
       " 'Donating to local charities that feed hungry children is a compassionate act.',\n",
       " 'Speaking kindly to those who are anxious can reduce their distress.',\n",
       " 'Adopting rescued farm animals to protect them from slaughter is morally praiseworthy.',\n",
       " 'Providing mental-health days for employees is a compassionate workplace policy.',\n",
       " 'Giving a comforting hug to someone who’s upset fosters empathy and connection.',\n",
       " 'Offering free tutoring to underprivileged students helps bridge educational gaps.',\n",
       " 'Advocating for animal rights by protesting cruel testing methods shows compassion.',\n",
       " 'Helping neighbors with household tasks when they’re injured demonstrates caring solidarity.',\n",
       " 'Encouraging support groups for trauma survivors shows moral concern.',\n",
       " \"Offering a meal to someone who hasn't eaten in days is a basic human kindness.\",\n",
       " 'Protecting stray animals from harsh weather is a duty of a compassionate community.',\n",
       " 'Creating inclusive playgrounds ensures that children with disabilities can play safely.',\n",
       " 'Taking time to check on elderly neighbors during severe weather is morally right.',\n",
       " 'Providing flexible scheduling for new parents supports the well-being of families.',\n",
       " 'Ensuring free access to safe drinking water is a moral priority.',\n",
       " 'Establishing community clinics that offer free vaccinations helps protect the vulnerable.',\n",
       " 'Designing public spaces that are friendly to those with mental and physical challenges fosters communal care.',\n",
       " 'Fundraising to cover medical costs for low-income families is an act of compassion.',\n",
       " \"Encouraging coworkers to rest when they're ill helps prevent further harm.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[stmt[\"statement\"] for stmt in get_moral_statements(dimension=\"care\", moral=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\"google/gemma-2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hook_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_analyzer = AblationAnalyzer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_pairs = moral_foundations['care']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_neurons_from_file(file_path: str) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Load list of (layer, neuron) tuples from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        neurons = json.load(f)\n",
    "    return [(int(layer), int(neuron)) for layer, neuron in neurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = load_neurons_from_file(\"../results/google-gemma-2-9b-it/2025-01-22_google-gemma-2-9b-it_fp16_moral-care_moral_neurons.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = ablation_analyzer.ablate_neurons(\n",
    "    text=\"The cat is sleeping.\", \n",
    "    neurons=neurons,\n",
    "    ablation_value=0.0\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ablation_analyzer.analyze_ablation_impact(\n",
    "    moral_pairs=moral_pairs,\n",
    "    neurons=neurons,\n",
    "    ablation_value=0.0\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.mft_dim import get_moral_statements\n",
    "get_moral_statements(dimension=\"care\", moral=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

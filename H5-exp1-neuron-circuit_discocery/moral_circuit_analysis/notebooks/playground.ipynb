{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../cm_train_contrastive_tupels.pkl', 'rb') as f:\n",
    "    list_moral_tupels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_moral_tupels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from data.mft_dim import moral_foundations, generate_mc_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generate_mc_prompts(moral_foundations, instruct_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import transformer_lens.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\"google/gemma-2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = 22\n",
    "print(dataset[entry][\"correct_answer\"])\n",
    "utils.test_prompt(dataset[entry][\"prompt\"], \" A\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.to_str_tokens( \" A, B,A,B\"))\n",
    "tokens = model.to_tokens(\" A, B,A,B\")\n",
    "print(tokens)\n",
    "model.to_string(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.run_with_cache(dataset[entry][\"prompt\"], return_type=\"logits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logits[0][0,-1,586])\n",
    "print(logits[0][0,-1,599])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.argmax(logits[0][0,-1,:]))\n",
    "prob = torch.softmax(logits[0][0,-1,:], dim=-1)\n",
    "print(prob)\n",
    "print(prob[586])\n",
    "print(prob[599])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = 0\n",
    "total = len(dataset)\n",
    "\n",
    "for idx, entry in enumerate(dataset):\n",
    "    # Get logits for the prompt\n",
    "    logits = model.run_with_cache(entry[\"prompt\"], return_type=\"logits\")\n",
    "    \n",
    "    # Get probabilities for the last position\n",
    "    probs = torch.softmax(logits[0][0,-1,:], dim=-1)\n",
    "    \n",
    "    # Get token IDs for \" A\" and \" B\"\n",
    "    token_A = 586  # Usually will be around 586\n",
    "    token_B = 599  # Usually will be around 599\n",
    "    \n",
    "    # Get the model's prediction (A or B based on higher probability)\n",
    "    pred = \"A\" if probs[token_A] > probs[token_B] else \"B\"\n",
    "    \n",
    "    # Compare with correct answer\n",
    "    is_correct = pred == entry[\"correct_answer\"]\n",
    "    correct_predictions += int(is_correct)\n",
    "    \n",
    "    print(f\"Entry {idx}: Predicted {pred}, Correct {entry['correct_answer']}, \"\n",
    "          f\"Prob A: {probs[token_A]:.3f}, Prob B: {probs[token_B]:.3f}, \"\n",
    "          f\"{'✓' if is_correct else '✗'}\")\n",
    "\n",
    "accuracy = correct_predictions / total\n",
    "print(f\"\\nOverall accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.mft_dim import get_moral_statements\n",
    "moral_statements = get_moral_statements(dimension=\"care\", moral=True)\n",
    "moral_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.test_prompt(moral_statements[0][\"prompt\"], \"agree\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_tokens(\"agree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Do you agree or disagree with the following Statement: One should never come to the aid of a stranger in distress. Moral dimension: care. Do agree or disagree? (max 15 words) \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "# Generate tokens\n",
    "num_tokens_to_generate = 60\n",
    "generated_text = model.generate(prompt, max_new_tokens=num_tokens_to_generate)\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store probabilities\n",
    "agree_probs = []\n",
    "disagree_probs = []\n",
    "generated_tokens = []\n",
    "\n",
    "# Get initial tokens\n",
    "tokens = model.to_tokens(prompt)\n",
    "initial_len = tokens.shape[1]\n",
    "\n",
    "# Generate one token at a time and get probabilities\n",
    "for i in range(num_tokens_to_generate):\n",
    "    # Get logits for next token\n",
    "    logits = model(tokens)[:,-1]\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Get probabilities for agree/disagree tokens\n",
    "    agree_token = model.to_tokens(\" agree\")[0,1]  \n",
    "    disagree_token = model.to_tokens(\" disagree\")[0,1]\n",
    "    \n",
    "    agree_prob = probs[0,agree_token].item()\n",
    "    disagree_prob = probs[0,disagree_token].item()\n",
    "    \n",
    "    agree_probs.append(agree_prob)\n",
    "    disagree_probs.append(disagree_prob)\n",
    "    \n",
    "    # Sample next token\n",
    "    next_token = torch.multinomial(probs[0], num_samples=1)\n",
    "    tokens = torch.cat([tokens, next_token.unsqueeze(0)], dim=1)\n",
    "    \n",
    "    # Store generated token\n",
    "    generated_tokens.append(model.to_string(next_token.unsqueeze(0)))\n",
    "    \n",
    "    # Break if EOS token generated\n",
    "    if next_token.item() == model.tokenizer.eos_token_id:\n",
    "        break\n",
    "\n",
    "# Print probabilities and tokens at each step\n",
    "for i, (token, agree_p, disagree_p) in enumerate(zip(generated_tokens, agree_probs, disagree_probs)):\n",
    "    print(f\"Position {i+initial_len} ({token}): Agree prob: {agree_p:.3f}, Disagree prob: {disagree_p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate total probabilities\n",
    "total_agree = sum(agree_probs)\n",
    "total_disagree = sum(disagree_probs)\n",
    "mean_agree = total_agree / len(agree_probs)\n",
    "mean_disagree = total_disagree / len(disagree_probs)\n",
    "highest_agree = max(agree_probs)\n",
    "highest_disagree = max(disagree_probs)\n",
    "\n",
    "print(f\"\\nMean probability for Agree: {mean_agree:.3f}\")\n",
    "print(f\"Mean probability for Disagree: {mean_disagree:.3f}\")\n",
    "\n",
    "print(f\"Highest probability for Agree: {highest_agree:.3f}\")\n",
    "print(f\"Highest probability for Disagree: {highest_disagree:.3f}\")\n",
    "\n",
    "print(f\"Total probability for Agree: {total_agree:.3f}\")\n",
    "print(f\"Total probability for Disagree: {total_disagree:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moral Analyzer whole sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from data.mft_dim import moral_foundations, generate_mc_prompts, get_moral_statements, get_moral_keys\n",
    "from src.analysis.moral_analyzer import MoralBehaviorAnalyzer\n",
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\"google/gemma-2-9b-it\", dtype=\"bf16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = MoralBehaviorAnalyzer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_moral_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"liberty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data list of moral statements and immoral statements\n",
    "moral_statements = get_moral_statements(dimension=category, moral=True)\n",
    "immoral_statements = get_moral_statements(dimension=category, moral=False)\n",
    "\n",
    "moral_pairs = [(statement[\"statement\"], immoral_statements[i][\"statement\"]) for i, statement in enumerate(moral_statements)]\n",
    "\n",
    "moral_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_pairs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyzer.analyze_moral_behavior(\n",
    "    moral_pairs,\n",
    "    temporal_window=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each key and its type to identify tensors and non-serializable objects\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {type(value)}\")\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"  Shape: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(results.get(\"activation_differences\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "from src.visualization.moral_neuron_viz import plot_moral_neuron_analysis\n",
    "plot_moral_neuron_analysis(results, moral_pairs, save_path=\"../results/2025-01-17_moral-\"+category+\"_neuron-analysis.png\", dimension=category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron Describer on base of the OAI Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from data.mft_dim import moral_foundations, generate_mc_prompts, get_moral_statements, get_moral_keys, get_neutral_statements\n",
    "from transformer_lens import HookedTransformer\n",
    "from src.analysis.neuron_describer_oai_v3 import ImprovedNeuronEvaluator, NeuronReport\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\"google/gemma-2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_statements = get_moral_statements()\n",
    "# Extract only statements in a list\n",
    "moral_statements = [statement[\"statement\"] for statement in moral_statements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_statements = get_neutral_statements()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ImprovedNeuronEvaluator(\n",
    "    model=model,\n",
    "    llm_name=\"gpt-4o\",\n",
    "    num_top_sequences=5,\n",
    "    batch_size=32,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    log_dir=\"../results/neuron_describer_logs\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 35\n",
    "neuron_idx = 9342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the 5 top activating sequences\n",
    "top_activations = evaluator.get_top_activating_sequences(layer=layer, neuron_idx=neuron_idx, texts=moral_statements)\n",
    "top_texts = [t.text for t in top_activations]\n",
    "top_activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random activating Features\n",
    "random_texts = random.sample([t for t in moral_statements if t not in top_activations], 5)\n",
    "random_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluator.evaluate_neuron(\n",
    "    layer=layer, \n",
    "    neuron_idx=neuron_idx, \n",
    "    texts=top_texts,\n",
    "    random_texts=neutral_statements,\n",
    "    revise=True\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tokens = [\n",
    "                f\"{act.token} ({act.activation:.3f})\"\n",
    "                for act in result.top_activations\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' | '.join(top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = NeuronReport(result)\n",
    "report.generate_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.save_report(\"../results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = evaluator.get_usage_stats()\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation of certain neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from data.mft_dim import moral_foundations, generate_mc_prompts, get_moral_statements, get_moral_keys, get_neutral_statements\n",
    "from transformer_lens import HookedTransformer\n",
    "from src.analysis.ablation import AblationAnalyzer\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One should always come to the aid of a stranger in distress.',\n",
       " 'Providing shelter and food to the homeless is our fundamental duty.',\n",
       " 'We should speak out against bullying to protect vulnerable individuals.',\n",
       " 'Inflicting physical harm on animals for entertainment is cruel and should be prohibited.',\n",
       " 'Every child deserves emotional support and reassurance during hard times.',\n",
       " 'Society should allocate resources to ensure that the sick receive proper medical care.',\n",
       " 'We have a moral responsibility to report and prevent abuse when we see it.',\n",
       " 'Comforting someone grieving a loss is a sign of basic human compassion.',\n",
       " 'Offering support to coworkers under stress fosters a more humane work environment.',\n",
       " 'Rescuing neglected pets and giving them care demonstrates moral empathy.',\n",
       " 'Responding kindly when someone makes an honest mistake prevents unnecessary harm.',\n",
       " 'Seeking help for mental health issues is important; we should encourage one another to do so.',\n",
       " 'Volunteering at shelters or community centers is a testament to compassion.',\n",
       " 'Offering a listening ear to someone who feels lonely upholds our shared humanity.',\n",
       " 'Stopping to help an injured animal on the road shows respect for life.',\n",
       " 'Donating blood or organs to save lives is an act of profound care.',\n",
       " 'Providing emotional support to disaster victims exemplifies moral decency.',\n",
       " 'Being patient and gentle with people in emotional distress helps prevent further harm.',\n",
       " 'We should teach children kindness by modeling empathy toward those who suffer.',\n",
       " 'Actively working to reduce harm in society, such as curbing pollution, is a moral imperative.',\n",
       " 'One should actively listen to friends who are experiencing emotional pain.',\n",
       " 'Donating to local charities that feed hungry children is a compassionate act.',\n",
       " 'Speaking kindly to those who are anxious can reduce their distress.',\n",
       " 'Adopting rescued farm animals to protect them from slaughter is morally praiseworthy.',\n",
       " 'Providing mental-health days for employees is a compassionate workplace policy.',\n",
       " 'Giving a comforting hug to someone who’s upset fosters empathy and connection.',\n",
       " 'Offering free tutoring to underprivileged students helps bridge educational gaps.',\n",
       " 'Advocating for animal rights by protesting cruel testing methods shows compassion.',\n",
       " 'Helping neighbors with household tasks when they’re injured demonstrates caring solidarity.',\n",
       " 'Encouraging support groups for trauma survivors shows moral concern.',\n",
       " \"Offering a meal to someone who hasn't eaten in days is a basic human kindness.\",\n",
       " 'Protecting stray animals from harsh weather is a duty of a compassionate community.',\n",
       " 'Creating inclusive playgrounds ensures that children with disabilities can play safely.',\n",
       " 'Taking time to check on elderly neighbors during severe weather is morally right.',\n",
       " 'Providing flexible scheduling for new parents supports the well-being of families.',\n",
       " 'Ensuring free access to safe drinking water is a moral priority.',\n",
       " 'Establishing community clinics that offer free vaccinations helps protect the vulnerable.',\n",
       " 'Designing public spaces that are friendly to those with mental and physical challenges fosters communal care.',\n",
       " 'Fundraising to cover medical costs for low-income families is an act of compassion.',\n",
       " \"Encouraging coworkers to rest when they're ill helps prevent further harm.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[stmt[\"statement\"] for stmt in get_moral_statements(dimension=\"care\", moral=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d97f8f19eb24b82b4c47febe363f512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/mech/lib/python3.10/site-packages/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-9b-it into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"google/gemma-2-9b-it\", device=\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hook_embed', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.ln1_post.hook_scale', 'blocks.0.ln1_post.hook_normalized', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.ln2_post.hook_scale', 'blocks.0.ln2_post.hook_normalized', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_z', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_result', 'blocks.0.attn.hook_rot_k', 'blocks.0.attn.hook_rot_q', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_pre_linear', 'blocks.0.mlp.hook_post', 'blocks.0.hook_attn_in', 'blocks.0.hook_q_input', 'blocks.0.hook_k_input', 'blocks.0.hook_v_input', 'blocks.0.hook_mlp_in', 'blocks.0.hook_attn_out', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_pre', 'blocks.0.hook_resid_mid', 'blocks.0.hook_resid_post', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.ln1_post.hook_scale', 'blocks.1.ln1_post.hook_normalized', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.ln2_post.hook_scale', 'blocks.1.ln2_post.hook_normalized', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_z', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_result', 'blocks.1.attn.hook_rot_k', 'blocks.1.attn.hook_rot_q', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_pre_linear', 'blocks.1.mlp.hook_post', 'blocks.1.hook_attn_in', 'blocks.1.hook_q_input', 'blocks.1.hook_k_input', 'blocks.1.hook_v_input', 'blocks.1.hook_mlp_in', 'blocks.1.hook_attn_out', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_pre', 'blocks.1.hook_resid_mid', 'blocks.1.hook_resid_post', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.ln1_post.hook_scale', 'blocks.2.ln1_post.hook_normalized', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.ln2_post.hook_scale', 'blocks.2.ln2_post.hook_normalized', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_z', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_result', 'blocks.2.attn.hook_rot_k', 'blocks.2.attn.hook_rot_q', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_pre_linear', 'blocks.2.mlp.hook_post', 'blocks.2.hook_attn_in', 'blocks.2.hook_q_input', 'blocks.2.hook_k_input', 'blocks.2.hook_v_input', 'blocks.2.hook_mlp_in', 'blocks.2.hook_attn_out', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_pre', 'blocks.2.hook_resid_mid', 'blocks.2.hook_resid_post', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.ln1_post.hook_scale', 'blocks.3.ln1_post.hook_normalized', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.ln2_post.hook_scale', 'blocks.3.ln2_post.hook_normalized', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_z', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_result', 'blocks.3.attn.hook_rot_k', 'blocks.3.attn.hook_rot_q', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_pre_linear', 'blocks.3.mlp.hook_post', 'blocks.3.hook_attn_in', 'blocks.3.hook_q_input', 'blocks.3.hook_k_input', 'blocks.3.hook_v_input', 'blocks.3.hook_mlp_in', 'blocks.3.hook_attn_out', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_pre', 'blocks.3.hook_resid_mid', 'blocks.3.hook_resid_post', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.ln1_post.hook_scale', 'blocks.4.ln1_post.hook_normalized', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.ln2_post.hook_scale', 'blocks.4.ln2_post.hook_normalized', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_z', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_result', 'blocks.4.attn.hook_rot_k', 'blocks.4.attn.hook_rot_q', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_pre_linear', 'blocks.4.mlp.hook_post', 'blocks.4.hook_attn_in', 'blocks.4.hook_q_input', 'blocks.4.hook_k_input', 'blocks.4.hook_v_input', 'blocks.4.hook_mlp_in', 'blocks.4.hook_attn_out', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_pre', 'blocks.4.hook_resid_mid', 'blocks.4.hook_resid_post', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.ln1_post.hook_scale', 'blocks.5.ln1_post.hook_normalized', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.ln2_post.hook_scale', 'blocks.5.ln2_post.hook_normalized', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_z', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_result', 'blocks.5.attn.hook_rot_k', 'blocks.5.attn.hook_rot_q', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_pre_linear', 'blocks.5.mlp.hook_post', 'blocks.5.hook_attn_in', 'blocks.5.hook_q_input', 'blocks.5.hook_k_input', 'blocks.5.hook_v_input', 'blocks.5.hook_mlp_in', 'blocks.5.hook_attn_out', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_pre', 'blocks.5.hook_resid_mid', 'blocks.5.hook_resid_post', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.ln1_post.hook_scale', 'blocks.6.ln1_post.hook_normalized', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.ln2_post.hook_scale', 'blocks.6.ln2_post.hook_normalized', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_z', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_result', 'blocks.6.attn.hook_rot_k', 'blocks.6.attn.hook_rot_q', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_pre_linear', 'blocks.6.mlp.hook_post', 'blocks.6.hook_attn_in', 'blocks.6.hook_q_input', 'blocks.6.hook_k_input', 'blocks.6.hook_v_input', 'blocks.6.hook_mlp_in', 'blocks.6.hook_attn_out', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_pre', 'blocks.6.hook_resid_mid', 'blocks.6.hook_resid_post', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.ln1_post.hook_scale', 'blocks.7.ln1_post.hook_normalized', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.ln2_post.hook_scale', 'blocks.7.ln2_post.hook_normalized', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_z', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_result', 'blocks.7.attn.hook_rot_k', 'blocks.7.attn.hook_rot_q', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_pre_linear', 'blocks.7.mlp.hook_post', 'blocks.7.hook_attn_in', 'blocks.7.hook_q_input', 'blocks.7.hook_k_input', 'blocks.7.hook_v_input', 'blocks.7.hook_mlp_in', 'blocks.7.hook_attn_out', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_pre', 'blocks.7.hook_resid_mid', 'blocks.7.hook_resid_post', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.ln1_post.hook_scale', 'blocks.8.ln1_post.hook_normalized', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.ln2_post.hook_scale', 'blocks.8.ln2_post.hook_normalized', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_z', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_result', 'blocks.8.attn.hook_rot_k', 'blocks.8.attn.hook_rot_q', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_pre_linear', 'blocks.8.mlp.hook_post', 'blocks.8.hook_attn_in', 'blocks.8.hook_q_input', 'blocks.8.hook_k_input', 'blocks.8.hook_v_input', 'blocks.8.hook_mlp_in', 'blocks.8.hook_attn_out', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_pre', 'blocks.8.hook_resid_mid', 'blocks.8.hook_resid_post', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.ln1_post.hook_scale', 'blocks.9.ln1_post.hook_normalized', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.ln2_post.hook_scale', 'blocks.9.ln2_post.hook_normalized', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_z', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_result', 'blocks.9.attn.hook_rot_k', 'blocks.9.attn.hook_rot_q', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_pre_linear', 'blocks.9.mlp.hook_post', 'blocks.9.hook_attn_in', 'blocks.9.hook_q_input', 'blocks.9.hook_k_input', 'blocks.9.hook_v_input', 'blocks.9.hook_mlp_in', 'blocks.9.hook_attn_out', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_pre', 'blocks.9.hook_resid_mid', 'blocks.9.hook_resid_post', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.ln1_post.hook_scale', 'blocks.10.ln1_post.hook_normalized', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.ln2_post.hook_scale', 'blocks.10.ln2_post.hook_normalized', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_z', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_result', 'blocks.10.attn.hook_rot_k', 'blocks.10.attn.hook_rot_q', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_pre_linear', 'blocks.10.mlp.hook_post', 'blocks.10.hook_attn_in', 'blocks.10.hook_q_input', 'blocks.10.hook_k_input', 'blocks.10.hook_v_input', 'blocks.10.hook_mlp_in', 'blocks.10.hook_attn_out', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_pre', 'blocks.10.hook_resid_mid', 'blocks.10.hook_resid_post', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.ln1_post.hook_scale', 'blocks.11.ln1_post.hook_normalized', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.ln2_post.hook_scale', 'blocks.11.ln2_post.hook_normalized', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_z', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_result', 'blocks.11.attn.hook_rot_k', 'blocks.11.attn.hook_rot_q', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_pre_linear', 'blocks.11.mlp.hook_post', 'blocks.11.hook_attn_in', 'blocks.11.hook_q_input', 'blocks.11.hook_k_input', 'blocks.11.hook_v_input', 'blocks.11.hook_mlp_in', 'blocks.11.hook_attn_out', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_pre', 'blocks.11.hook_resid_mid', 'blocks.11.hook_resid_post', 'blocks.12.ln1.hook_scale', 'blocks.12.ln1.hook_normalized', 'blocks.12.ln1_post.hook_scale', 'blocks.12.ln1_post.hook_normalized', 'blocks.12.ln2.hook_scale', 'blocks.12.ln2.hook_normalized', 'blocks.12.ln2_post.hook_scale', 'blocks.12.ln2_post.hook_normalized', 'blocks.12.attn.hook_k', 'blocks.12.attn.hook_q', 'blocks.12.attn.hook_v', 'blocks.12.attn.hook_z', 'blocks.12.attn.hook_attn_scores', 'blocks.12.attn.hook_pattern', 'blocks.12.attn.hook_result', 'blocks.12.attn.hook_rot_k', 'blocks.12.attn.hook_rot_q', 'blocks.12.mlp.hook_pre', 'blocks.12.mlp.hook_pre_linear', 'blocks.12.mlp.hook_post', 'blocks.12.hook_attn_in', 'blocks.12.hook_q_input', 'blocks.12.hook_k_input', 'blocks.12.hook_v_input', 'blocks.12.hook_mlp_in', 'blocks.12.hook_attn_out', 'blocks.12.hook_mlp_out', 'blocks.12.hook_resid_pre', 'blocks.12.hook_resid_mid', 'blocks.12.hook_resid_post', 'blocks.13.ln1.hook_scale', 'blocks.13.ln1.hook_normalized', 'blocks.13.ln1_post.hook_scale', 'blocks.13.ln1_post.hook_normalized', 'blocks.13.ln2.hook_scale', 'blocks.13.ln2.hook_normalized', 'blocks.13.ln2_post.hook_scale', 'blocks.13.ln2_post.hook_normalized', 'blocks.13.attn.hook_k', 'blocks.13.attn.hook_q', 'blocks.13.attn.hook_v', 'blocks.13.attn.hook_z', 'blocks.13.attn.hook_attn_scores', 'blocks.13.attn.hook_pattern', 'blocks.13.attn.hook_result', 'blocks.13.attn.hook_rot_k', 'blocks.13.attn.hook_rot_q', 'blocks.13.mlp.hook_pre', 'blocks.13.mlp.hook_pre_linear', 'blocks.13.mlp.hook_post', 'blocks.13.hook_attn_in', 'blocks.13.hook_q_input', 'blocks.13.hook_k_input', 'blocks.13.hook_v_input', 'blocks.13.hook_mlp_in', 'blocks.13.hook_attn_out', 'blocks.13.hook_mlp_out', 'blocks.13.hook_resid_pre', 'blocks.13.hook_resid_mid', 'blocks.13.hook_resid_post', 'blocks.14.ln1.hook_scale', 'blocks.14.ln1.hook_normalized', 'blocks.14.ln1_post.hook_scale', 'blocks.14.ln1_post.hook_normalized', 'blocks.14.ln2.hook_scale', 'blocks.14.ln2.hook_normalized', 'blocks.14.ln2_post.hook_scale', 'blocks.14.ln2_post.hook_normalized', 'blocks.14.attn.hook_k', 'blocks.14.attn.hook_q', 'blocks.14.attn.hook_v', 'blocks.14.attn.hook_z', 'blocks.14.attn.hook_attn_scores', 'blocks.14.attn.hook_pattern', 'blocks.14.attn.hook_result', 'blocks.14.attn.hook_rot_k', 'blocks.14.attn.hook_rot_q', 'blocks.14.mlp.hook_pre', 'blocks.14.mlp.hook_pre_linear', 'blocks.14.mlp.hook_post', 'blocks.14.hook_attn_in', 'blocks.14.hook_q_input', 'blocks.14.hook_k_input', 'blocks.14.hook_v_input', 'blocks.14.hook_mlp_in', 'blocks.14.hook_attn_out', 'blocks.14.hook_mlp_out', 'blocks.14.hook_resid_pre', 'blocks.14.hook_resid_mid', 'blocks.14.hook_resid_post', 'blocks.15.ln1.hook_scale', 'blocks.15.ln1.hook_normalized', 'blocks.15.ln1_post.hook_scale', 'blocks.15.ln1_post.hook_normalized', 'blocks.15.ln2.hook_scale', 'blocks.15.ln2.hook_normalized', 'blocks.15.ln2_post.hook_scale', 'blocks.15.ln2_post.hook_normalized', 'blocks.15.attn.hook_k', 'blocks.15.attn.hook_q', 'blocks.15.attn.hook_v', 'blocks.15.attn.hook_z', 'blocks.15.attn.hook_attn_scores', 'blocks.15.attn.hook_pattern', 'blocks.15.attn.hook_result', 'blocks.15.attn.hook_rot_k', 'blocks.15.attn.hook_rot_q', 'blocks.15.mlp.hook_pre', 'blocks.15.mlp.hook_pre_linear', 'blocks.15.mlp.hook_post', 'blocks.15.hook_attn_in', 'blocks.15.hook_q_input', 'blocks.15.hook_k_input', 'blocks.15.hook_v_input', 'blocks.15.hook_mlp_in', 'blocks.15.hook_attn_out', 'blocks.15.hook_mlp_out', 'blocks.15.hook_resid_pre', 'blocks.15.hook_resid_mid', 'blocks.15.hook_resid_post', 'blocks.16.ln1.hook_scale', 'blocks.16.ln1.hook_normalized', 'blocks.16.ln1_post.hook_scale', 'blocks.16.ln1_post.hook_normalized', 'blocks.16.ln2.hook_scale', 'blocks.16.ln2.hook_normalized', 'blocks.16.ln2_post.hook_scale', 'blocks.16.ln2_post.hook_normalized', 'blocks.16.attn.hook_k', 'blocks.16.attn.hook_q', 'blocks.16.attn.hook_v', 'blocks.16.attn.hook_z', 'blocks.16.attn.hook_attn_scores', 'blocks.16.attn.hook_pattern', 'blocks.16.attn.hook_result', 'blocks.16.attn.hook_rot_k', 'blocks.16.attn.hook_rot_q', 'blocks.16.mlp.hook_pre', 'blocks.16.mlp.hook_pre_linear', 'blocks.16.mlp.hook_post', 'blocks.16.hook_attn_in', 'blocks.16.hook_q_input', 'blocks.16.hook_k_input', 'blocks.16.hook_v_input', 'blocks.16.hook_mlp_in', 'blocks.16.hook_attn_out', 'blocks.16.hook_mlp_out', 'blocks.16.hook_resid_pre', 'blocks.16.hook_resid_mid', 'blocks.16.hook_resid_post', 'blocks.17.ln1.hook_scale', 'blocks.17.ln1.hook_normalized', 'blocks.17.ln1_post.hook_scale', 'blocks.17.ln1_post.hook_normalized', 'blocks.17.ln2.hook_scale', 'blocks.17.ln2.hook_normalized', 'blocks.17.ln2_post.hook_scale', 'blocks.17.ln2_post.hook_normalized', 'blocks.17.attn.hook_k', 'blocks.17.attn.hook_q', 'blocks.17.attn.hook_v', 'blocks.17.attn.hook_z', 'blocks.17.attn.hook_attn_scores', 'blocks.17.attn.hook_pattern', 'blocks.17.attn.hook_result', 'blocks.17.attn.hook_rot_k', 'blocks.17.attn.hook_rot_q', 'blocks.17.mlp.hook_pre', 'blocks.17.mlp.hook_pre_linear', 'blocks.17.mlp.hook_post', 'blocks.17.hook_attn_in', 'blocks.17.hook_q_input', 'blocks.17.hook_k_input', 'blocks.17.hook_v_input', 'blocks.17.hook_mlp_in', 'blocks.17.hook_attn_out', 'blocks.17.hook_mlp_out', 'blocks.17.hook_resid_pre', 'blocks.17.hook_resid_mid', 'blocks.17.hook_resid_post', 'blocks.18.ln1.hook_scale', 'blocks.18.ln1.hook_normalized', 'blocks.18.ln1_post.hook_scale', 'blocks.18.ln1_post.hook_normalized', 'blocks.18.ln2.hook_scale', 'blocks.18.ln2.hook_normalized', 'blocks.18.ln2_post.hook_scale', 'blocks.18.ln2_post.hook_normalized', 'blocks.18.attn.hook_k', 'blocks.18.attn.hook_q', 'blocks.18.attn.hook_v', 'blocks.18.attn.hook_z', 'blocks.18.attn.hook_attn_scores', 'blocks.18.attn.hook_pattern', 'blocks.18.attn.hook_result', 'blocks.18.attn.hook_rot_k', 'blocks.18.attn.hook_rot_q', 'blocks.18.mlp.hook_pre', 'blocks.18.mlp.hook_pre_linear', 'blocks.18.mlp.hook_post', 'blocks.18.hook_attn_in', 'blocks.18.hook_q_input', 'blocks.18.hook_k_input', 'blocks.18.hook_v_input', 'blocks.18.hook_mlp_in', 'blocks.18.hook_attn_out', 'blocks.18.hook_mlp_out', 'blocks.18.hook_resid_pre', 'blocks.18.hook_resid_mid', 'blocks.18.hook_resid_post', 'blocks.19.ln1.hook_scale', 'blocks.19.ln1.hook_normalized', 'blocks.19.ln1_post.hook_scale', 'blocks.19.ln1_post.hook_normalized', 'blocks.19.ln2.hook_scale', 'blocks.19.ln2.hook_normalized', 'blocks.19.ln2_post.hook_scale', 'blocks.19.ln2_post.hook_normalized', 'blocks.19.attn.hook_k', 'blocks.19.attn.hook_q', 'blocks.19.attn.hook_v', 'blocks.19.attn.hook_z', 'blocks.19.attn.hook_attn_scores', 'blocks.19.attn.hook_pattern', 'blocks.19.attn.hook_result', 'blocks.19.attn.hook_rot_k', 'blocks.19.attn.hook_rot_q', 'blocks.19.mlp.hook_pre', 'blocks.19.mlp.hook_pre_linear', 'blocks.19.mlp.hook_post', 'blocks.19.hook_attn_in', 'blocks.19.hook_q_input', 'blocks.19.hook_k_input', 'blocks.19.hook_v_input', 'blocks.19.hook_mlp_in', 'blocks.19.hook_attn_out', 'blocks.19.hook_mlp_out', 'blocks.19.hook_resid_pre', 'blocks.19.hook_resid_mid', 'blocks.19.hook_resid_post', 'blocks.20.ln1.hook_scale', 'blocks.20.ln1.hook_normalized', 'blocks.20.ln1_post.hook_scale', 'blocks.20.ln1_post.hook_normalized', 'blocks.20.ln2.hook_scale', 'blocks.20.ln2.hook_normalized', 'blocks.20.ln2_post.hook_scale', 'blocks.20.ln2_post.hook_normalized', 'blocks.20.attn.hook_k', 'blocks.20.attn.hook_q', 'blocks.20.attn.hook_v', 'blocks.20.attn.hook_z', 'blocks.20.attn.hook_attn_scores', 'blocks.20.attn.hook_pattern', 'blocks.20.attn.hook_result', 'blocks.20.attn.hook_rot_k', 'blocks.20.attn.hook_rot_q', 'blocks.20.mlp.hook_pre', 'blocks.20.mlp.hook_pre_linear', 'blocks.20.mlp.hook_post', 'blocks.20.hook_attn_in', 'blocks.20.hook_q_input', 'blocks.20.hook_k_input', 'blocks.20.hook_v_input', 'blocks.20.hook_mlp_in', 'blocks.20.hook_attn_out', 'blocks.20.hook_mlp_out', 'blocks.20.hook_resid_pre', 'blocks.20.hook_resid_mid', 'blocks.20.hook_resid_post', 'blocks.21.ln1.hook_scale', 'blocks.21.ln1.hook_normalized', 'blocks.21.ln1_post.hook_scale', 'blocks.21.ln1_post.hook_normalized', 'blocks.21.ln2.hook_scale', 'blocks.21.ln2.hook_normalized', 'blocks.21.ln2_post.hook_scale', 'blocks.21.ln2_post.hook_normalized', 'blocks.21.attn.hook_k', 'blocks.21.attn.hook_q', 'blocks.21.attn.hook_v', 'blocks.21.attn.hook_z', 'blocks.21.attn.hook_attn_scores', 'blocks.21.attn.hook_pattern', 'blocks.21.attn.hook_result', 'blocks.21.attn.hook_rot_k', 'blocks.21.attn.hook_rot_q', 'blocks.21.mlp.hook_pre', 'blocks.21.mlp.hook_pre_linear', 'blocks.21.mlp.hook_post', 'blocks.21.hook_attn_in', 'blocks.21.hook_q_input', 'blocks.21.hook_k_input', 'blocks.21.hook_v_input', 'blocks.21.hook_mlp_in', 'blocks.21.hook_attn_out', 'blocks.21.hook_mlp_out', 'blocks.21.hook_resid_pre', 'blocks.21.hook_resid_mid', 'blocks.21.hook_resid_post', 'blocks.22.ln1.hook_scale', 'blocks.22.ln1.hook_normalized', 'blocks.22.ln1_post.hook_scale', 'blocks.22.ln1_post.hook_normalized', 'blocks.22.ln2.hook_scale', 'blocks.22.ln2.hook_normalized', 'blocks.22.ln2_post.hook_scale', 'blocks.22.ln2_post.hook_normalized', 'blocks.22.attn.hook_k', 'blocks.22.attn.hook_q', 'blocks.22.attn.hook_v', 'blocks.22.attn.hook_z', 'blocks.22.attn.hook_attn_scores', 'blocks.22.attn.hook_pattern', 'blocks.22.attn.hook_result', 'blocks.22.attn.hook_rot_k', 'blocks.22.attn.hook_rot_q', 'blocks.22.mlp.hook_pre', 'blocks.22.mlp.hook_pre_linear', 'blocks.22.mlp.hook_post', 'blocks.22.hook_attn_in', 'blocks.22.hook_q_input', 'blocks.22.hook_k_input', 'blocks.22.hook_v_input', 'blocks.22.hook_mlp_in', 'blocks.22.hook_attn_out', 'blocks.22.hook_mlp_out', 'blocks.22.hook_resid_pre', 'blocks.22.hook_resid_mid', 'blocks.22.hook_resid_post', 'blocks.23.ln1.hook_scale', 'blocks.23.ln1.hook_normalized', 'blocks.23.ln1_post.hook_scale', 'blocks.23.ln1_post.hook_normalized', 'blocks.23.ln2.hook_scale', 'blocks.23.ln2.hook_normalized', 'blocks.23.ln2_post.hook_scale', 'blocks.23.ln2_post.hook_normalized', 'blocks.23.attn.hook_k', 'blocks.23.attn.hook_q', 'blocks.23.attn.hook_v', 'blocks.23.attn.hook_z', 'blocks.23.attn.hook_attn_scores', 'blocks.23.attn.hook_pattern', 'blocks.23.attn.hook_result', 'blocks.23.attn.hook_rot_k', 'blocks.23.attn.hook_rot_q', 'blocks.23.mlp.hook_pre', 'blocks.23.mlp.hook_pre_linear', 'blocks.23.mlp.hook_post', 'blocks.23.hook_attn_in', 'blocks.23.hook_q_input', 'blocks.23.hook_k_input', 'blocks.23.hook_v_input', 'blocks.23.hook_mlp_in', 'blocks.23.hook_attn_out', 'blocks.23.hook_mlp_out', 'blocks.23.hook_resid_pre', 'blocks.23.hook_resid_mid', 'blocks.23.hook_resid_post', 'blocks.24.ln1.hook_scale', 'blocks.24.ln1.hook_normalized', 'blocks.24.ln1_post.hook_scale', 'blocks.24.ln1_post.hook_normalized', 'blocks.24.ln2.hook_scale', 'blocks.24.ln2.hook_normalized', 'blocks.24.ln2_post.hook_scale', 'blocks.24.ln2_post.hook_normalized', 'blocks.24.attn.hook_k', 'blocks.24.attn.hook_q', 'blocks.24.attn.hook_v', 'blocks.24.attn.hook_z', 'blocks.24.attn.hook_attn_scores', 'blocks.24.attn.hook_pattern', 'blocks.24.attn.hook_result', 'blocks.24.attn.hook_rot_k', 'blocks.24.attn.hook_rot_q', 'blocks.24.mlp.hook_pre', 'blocks.24.mlp.hook_pre_linear', 'blocks.24.mlp.hook_post', 'blocks.24.hook_attn_in', 'blocks.24.hook_q_input', 'blocks.24.hook_k_input', 'blocks.24.hook_v_input', 'blocks.24.hook_mlp_in', 'blocks.24.hook_attn_out', 'blocks.24.hook_mlp_out', 'blocks.24.hook_resid_pre', 'blocks.24.hook_resid_mid', 'blocks.24.hook_resid_post', 'blocks.25.ln1.hook_scale', 'blocks.25.ln1.hook_normalized', 'blocks.25.ln1_post.hook_scale', 'blocks.25.ln1_post.hook_normalized', 'blocks.25.ln2.hook_scale', 'blocks.25.ln2.hook_normalized', 'blocks.25.ln2_post.hook_scale', 'blocks.25.ln2_post.hook_normalized', 'blocks.25.attn.hook_k', 'blocks.25.attn.hook_q', 'blocks.25.attn.hook_v', 'blocks.25.attn.hook_z', 'blocks.25.attn.hook_attn_scores', 'blocks.25.attn.hook_pattern', 'blocks.25.attn.hook_result', 'blocks.25.attn.hook_rot_k', 'blocks.25.attn.hook_rot_q', 'blocks.25.mlp.hook_pre', 'blocks.25.mlp.hook_pre_linear', 'blocks.25.mlp.hook_post', 'blocks.25.hook_attn_in', 'blocks.25.hook_q_input', 'blocks.25.hook_k_input', 'blocks.25.hook_v_input', 'blocks.25.hook_mlp_in', 'blocks.25.hook_attn_out', 'blocks.25.hook_mlp_out', 'blocks.25.hook_resid_pre', 'blocks.25.hook_resid_mid', 'blocks.25.hook_resid_post', 'blocks.26.ln1.hook_scale', 'blocks.26.ln1.hook_normalized', 'blocks.26.ln1_post.hook_scale', 'blocks.26.ln1_post.hook_normalized', 'blocks.26.ln2.hook_scale', 'blocks.26.ln2.hook_normalized', 'blocks.26.ln2_post.hook_scale', 'blocks.26.ln2_post.hook_normalized', 'blocks.26.attn.hook_k', 'blocks.26.attn.hook_q', 'blocks.26.attn.hook_v', 'blocks.26.attn.hook_z', 'blocks.26.attn.hook_attn_scores', 'blocks.26.attn.hook_pattern', 'blocks.26.attn.hook_result', 'blocks.26.attn.hook_rot_k', 'blocks.26.attn.hook_rot_q', 'blocks.26.mlp.hook_pre', 'blocks.26.mlp.hook_pre_linear', 'blocks.26.mlp.hook_post', 'blocks.26.hook_attn_in', 'blocks.26.hook_q_input', 'blocks.26.hook_k_input', 'blocks.26.hook_v_input', 'blocks.26.hook_mlp_in', 'blocks.26.hook_attn_out', 'blocks.26.hook_mlp_out', 'blocks.26.hook_resid_pre', 'blocks.26.hook_resid_mid', 'blocks.26.hook_resid_post', 'blocks.27.ln1.hook_scale', 'blocks.27.ln1.hook_normalized', 'blocks.27.ln1_post.hook_scale', 'blocks.27.ln1_post.hook_normalized', 'blocks.27.ln2.hook_scale', 'blocks.27.ln2.hook_normalized', 'blocks.27.ln2_post.hook_scale', 'blocks.27.ln2_post.hook_normalized', 'blocks.27.attn.hook_k', 'blocks.27.attn.hook_q', 'blocks.27.attn.hook_v', 'blocks.27.attn.hook_z', 'blocks.27.attn.hook_attn_scores', 'blocks.27.attn.hook_pattern', 'blocks.27.attn.hook_result', 'blocks.27.attn.hook_rot_k', 'blocks.27.attn.hook_rot_q', 'blocks.27.mlp.hook_pre', 'blocks.27.mlp.hook_pre_linear', 'blocks.27.mlp.hook_post', 'blocks.27.hook_attn_in', 'blocks.27.hook_q_input', 'blocks.27.hook_k_input', 'blocks.27.hook_v_input', 'blocks.27.hook_mlp_in', 'blocks.27.hook_attn_out', 'blocks.27.hook_mlp_out', 'blocks.27.hook_resid_pre', 'blocks.27.hook_resid_mid', 'blocks.27.hook_resid_post', 'blocks.28.ln1.hook_scale', 'blocks.28.ln1.hook_normalized', 'blocks.28.ln1_post.hook_scale', 'blocks.28.ln1_post.hook_normalized', 'blocks.28.ln2.hook_scale', 'blocks.28.ln2.hook_normalized', 'blocks.28.ln2_post.hook_scale', 'blocks.28.ln2_post.hook_normalized', 'blocks.28.attn.hook_k', 'blocks.28.attn.hook_q', 'blocks.28.attn.hook_v', 'blocks.28.attn.hook_z', 'blocks.28.attn.hook_attn_scores', 'blocks.28.attn.hook_pattern', 'blocks.28.attn.hook_result', 'blocks.28.attn.hook_rot_k', 'blocks.28.attn.hook_rot_q', 'blocks.28.mlp.hook_pre', 'blocks.28.mlp.hook_pre_linear', 'blocks.28.mlp.hook_post', 'blocks.28.hook_attn_in', 'blocks.28.hook_q_input', 'blocks.28.hook_k_input', 'blocks.28.hook_v_input', 'blocks.28.hook_mlp_in', 'blocks.28.hook_attn_out', 'blocks.28.hook_mlp_out', 'blocks.28.hook_resid_pre', 'blocks.28.hook_resid_mid', 'blocks.28.hook_resid_post', 'blocks.29.ln1.hook_scale', 'blocks.29.ln1.hook_normalized', 'blocks.29.ln1_post.hook_scale', 'blocks.29.ln1_post.hook_normalized', 'blocks.29.ln2.hook_scale', 'blocks.29.ln2.hook_normalized', 'blocks.29.ln2_post.hook_scale', 'blocks.29.ln2_post.hook_normalized', 'blocks.29.attn.hook_k', 'blocks.29.attn.hook_q', 'blocks.29.attn.hook_v', 'blocks.29.attn.hook_z', 'blocks.29.attn.hook_attn_scores', 'blocks.29.attn.hook_pattern', 'blocks.29.attn.hook_result', 'blocks.29.attn.hook_rot_k', 'blocks.29.attn.hook_rot_q', 'blocks.29.mlp.hook_pre', 'blocks.29.mlp.hook_pre_linear', 'blocks.29.mlp.hook_post', 'blocks.29.hook_attn_in', 'blocks.29.hook_q_input', 'blocks.29.hook_k_input', 'blocks.29.hook_v_input', 'blocks.29.hook_mlp_in', 'blocks.29.hook_attn_out', 'blocks.29.hook_mlp_out', 'blocks.29.hook_resid_pre', 'blocks.29.hook_resid_mid', 'blocks.29.hook_resid_post', 'blocks.30.ln1.hook_scale', 'blocks.30.ln1.hook_normalized', 'blocks.30.ln1_post.hook_scale', 'blocks.30.ln1_post.hook_normalized', 'blocks.30.ln2.hook_scale', 'blocks.30.ln2.hook_normalized', 'blocks.30.ln2_post.hook_scale', 'blocks.30.ln2_post.hook_normalized', 'blocks.30.attn.hook_k', 'blocks.30.attn.hook_q', 'blocks.30.attn.hook_v', 'blocks.30.attn.hook_z', 'blocks.30.attn.hook_attn_scores', 'blocks.30.attn.hook_pattern', 'blocks.30.attn.hook_result', 'blocks.30.attn.hook_rot_k', 'blocks.30.attn.hook_rot_q', 'blocks.30.mlp.hook_pre', 'blocks.30.mlp.hook_pre_linear', 'blocks.30.mlp.hook_post', 'blocks.30.hook_attn_in', 'blocks.30.hook_q_input', 'blocks.30.hook_k_input', 'blocks.30.hook_v_input', 'blocks.30.hook_mlp_in', 'blocks.30.hook_attn_out', 'blocks.30.hook_mlp_out', 'blocks.30.hook_resid_pre', 'blocks.30.hook_resid_mid', 'blocks.30.hook_resid_post', 'blocks.31.ln1.hook_scale', 'blocks.31.ln1.hook_normalized', 'blocks.31.ln1_post.hook_scale', 'blocks.31.ln1_post.hook_normalized', 'blocks.31.ln2.hook_scale', 'blocks.31.ln2.hook_normalized', 'blocks.31.ln2_post.hook_scale', 'blocks.31.ln2_post.hook_normalized', 'blocks.31.attn.hook_k', 'blocks.31.attn.hook_q', 'blocks.31.attn.hook_v', 'blocks.31.attn.hook_z', 'blocks.31.attn.hook_attn_scores', 'blocks.31.attn.hook_pattern', 'blocks.31.attn.hook_result', 'blocks.31.attn.hook_rot_k', 'blocks.31.attn.hook_rot_q', 'blocks.31.mlp.hook_pre', 'blocks.31.mlp.hook_pre_linear', 'blocks.31.mlp.hook_post', 'blocks.31.hook_attn_in', 'blocks.31.hook_q_input', 'blocks.31.hook_k_input', 'blocks.31.hook_v_input', 'blocks.31.hook_mlp_in', 'blocks.31.hook_attn_out', 'blocks.31.hook_mlp_out', 'blocks.31.hook_resid_pre', 'blocks.31.hook_resid_mid', 'blocks.31.hook_resid_post', 'blocks.32.ln1.hook_scale', 'blocks.32.ln1.hook_normalized', 'blocks.32.ln1_post.hook_scale', 'blocks.32.ln1_post.hook_normalized', 'blocks.32.ln2.hook_scale', 'blocks.32.ln2.hook_normalized', 'blocks.32.ln2_post.hook_scale', 'blocks.32.ln2_post.hook_normalized', 'blocks.32.attn.hook_k', 'blocks.32.attn.hook_q', 'blocks.32.attn.hook_v', 'blocks.32.attn.hook_z', 'blocks.32.attn.hook_attn_scores', 'blocks.32.attn.hook_pattern', 'blocks.32.attn.hook_result', 'blocks.32.attn.hook_rot_k', 'blocks.32.attn.hook_rot_q', 'blocks.32.mlp.hook_pre', 'blocks.32.mlp.hook_pre_linear', 'blocks.32.mlp.hook_post', 'blocks.32.hook_attn_in', 'blocks.32.hook_q_input', 'blocks.32.hook_k_input', 'blocks.32.hook_v_input', 'blocks.32.hook_mlp_in', 'blocks.32.hook_attn_out', 'blocks.32.hook_mlp_out', 'blocks.32.hook_resid_pre', 'blocks.32.hook_resid_mid', 'blocks.32.hook_resid_post', 'blocks.33.ln1.hook_scale', 'blocks.33.ln1.hook_normalized', 'blocks.33.ln1_post.hook_scale', 'blocks.33.ln1_post.hook_normalized', 'blocks.33.ln2.hook_scale', 'blocks.33.ln2.hook_normalized', 'blocks.33.ln2_post.hook_scale', 'blocks.33.ln2_post.hook_normalized', 'blocks.33.attn.hook_k', 'blocks.33.attn.hook_q', 'blocks.33.attn.hook_v', 'blocks.33.attn.hook_z', 'blocks.33.attn.hook_attn_scores', 'blocks.33.attn.hook_pattern', 'blocks.33.attn.hook_result', 'blocks.33.attn.hook_rot_k', 'blocks.33.attn.hook_rot_q', 'blocks.33.mlp.hook_pre', 'blocks.33.mlp.hook_pre_linear', 'blocks.33.mlp.hook_post', 'blocks.33.hook_attn_in', 'blocks.33.hook_q_input', 'blocks.33.hook_k_input', 'blocks.33.hook_v_input', 'blocks.33.hook_mlp_in', 'blocks.33.hook_attn_out', 'blocks.33.hook_mlp_out', 'blocks.33.hook_resid_pre', 'blocks.33.hook_resid_mid', 'blocks.33.hook_resid_post', 'blocks.34.ln1.hook_scale', 'blocks.34.ln1.hook_normalized', 'blocks.34.ln1_post.hook_scale', 'blocks.34.ln1_post.hook_normalized', 'blocks.34.ln2.hook_scale', 'blocks.34.ln2.hook_normalized', 'blocks.34.ln2_post.hook_scale', 'blocks.34.ln2_post.hook_normalized', 'blocks.34.attn.hook_k', 'blocks.34.attn.hook_q', 'blocks.34.attn.hook_v', 'blocks.34.attn.hook_z', 'blocks.34.attn.hook_attn_scores', 'blocks.34.attn.hook_pattern', 'blocks.34.attn.hook_result', 'blocks.34.attn.hook_rot_k', 'blocks.34.attn.hook_rot_q', 'blocks.34.mlp.hook_pre', 'blocks.34.mlp.hook_pre_linear', 'blocks.34.mlp.hook_post', 'blocks.34.hook_attn_in', 'blocks.34.hook_q_input', 'blocks.34.hook_k_input', 'blocks.34.hook_v_input', 'blocks.34.hook_mlp_in', 'blocks.34.hook_attn_out', 'blocks.34.hook_mlp_out', 'blocks.34.hook_resid_pre', 'blocks.34.hook_resid_mid', 'blocks.34.hook_resid_post', 'blocks.35.ln1.hook_scale', 'blocks.35.ln1.hook_normalized', 'blocks.35.ln1_post.hook_scale', 'blocks.35.ln1_post.hook_normalized', 'blocks.35.ln2.hook_scale', 'blocks.35.ln2.hook_normalized', 'blocks.35.ln2_post.hook_scale', 'blocks.35.ln2_post.hook_normalized', 'blocks.35.attn.hook_k', 'blocks.35.attn.hook_q', 'blocks.35.attn.hook_v', 'blocks.35.attn.hook_z', 'blocks.35.attn.hook_attn_scores', 'blocks.35.attn.hook_pattern', 'blocks.35.attn.hook_result', 'blocks.35.attn.hook_rot_k', 'blocks.35.attn.hook_rot_q', 'blocks.35.mlp.hook_pre', 'blocks.35.mlp.hook_pre_linear', 'blocks.35.mlp.hook_post', 'blocks.35.hook_attn_in', 'blocks.35.hook_q_input', 'blocks.35.hook_k_input', 'blocks.35.hook_v_input', 'blocks.35.hook_mlp_in', 'blocks.35.hook_attn_out', 'blocks.35.hook_mlp_out', 'blocks.35.hook_resid_pre', 'blocks.35.hook_resid_mid', 'blocks.35.hook_resid_post', 'blocks.36.ln1.hook_scale', 'blocks.36.ln1.hook_normalized', 'blocks.36.ln1_post.hook_scale', 'blocks.36.ln1_post.hook_normalized', 'blocks.36.ln2.hook_scale', 'blocks.36.ln2.hook_normalized', 'blocks.36.ln2_post.hook_scale', 'blocks.36.ln2_post.hook_normalized', 'blocks.36.attn.hook_k', 'blocks.36.attn.hook_q', 'blocks.36.attn.hook_v', 'blocks.36.attn.hook_z', 'blocks.36.attn.hook_attn_scores', 'blocks.36.attn.hook_pattern', 'blocks.36.attn.hook_result', 'blocks.36.attn.hook_rot_k', 'blocks.36.attn.hook_rot_q', 'blocks.36.mlp.hook_pre', 'blocks.36.mlp.hook_pre_linear', 'blocks.36.mlp.hook_post', 'blocks.36.hook_attn_in', 'blocks.36.hook_q_input', 'blocks.36.hook_k_input', 'blocks.36.hook_v_input', 'blocks.36.hook_mlp_in', 'blocks.36.hook_attn_out', 'blocks.36.hook_mlp_out', 'blocks.36.hook_resid_pre', 'blocks.36.hook_resid_mid', 'blocks.36.hook_resid_post', 'blocks.37.ln1.hook_scale', 'blocks.37.ln1.hook_normalized', 'blocks.37.ln1_post.hook_scale', 'blocks.37.ln1_post.hook_normalized', 'blocks.37.ln2.hook_scale', 'blocks.37.ln2.hook_normalized', 'blocks.37.ln2_post.hook_scale', 'blocks.37.ln2_post.hook_normalized', 'blocks.37.attn.hook_k', 'blocks.37.attn.hook_q', 'blocks.37.attn.hook_v', 'blocks.37.attn.hook_z', 'blocks.37.attn.hook_attn_scores', 'blocks.37.attn.hook_pattern', 'blocks.37.attn.hook_result', 'blocks.37.attn.hook_rot_k', 'blocks.37.attn.hook_rot_q', 'blocks.37.mlp.hook_pre', 'blocks.37.mlp.hook_pre_linear', 'blocks.37.mlp.hook_post', 'blocks.37.hook_attn_in', 'blocks.37.hook_q_input', 'blocks.37.hook_k_input', 'blocks.37.hook_v_input', 'blocks.37.hook_mlp_in', 'blocks.37.hook_attn_out', 'blocks.37.hook_mlp_out', 'blocks.37.hook_resid_pre', 'blocks.37.hook_resid_mid', 'blocks.37.hook_resid_post', 'blocks.38.ln1.hook_scale', 'blocks.38.ln1.hook_normalized', 'blocks.38.ln1_post.hook_scale', 'blocks.38.ln1_post.hook_normalized', 'blocks.38.ln2.hook_scale', 'blocks.38.ln2.hook_normalized', 'blocks.38.ln2_post.hook_scale', 'blocks.38.ln2_post.hook_normalized', 'blocks.38.attn.hook_k', 'blocks.38.attn.hook_q', 'blocks.38.attn.hook_v', 'blocks.38.attn.hook_z', 'blocks.38.attn.hook_attn_scores', 'blocks.38.attn.hook_pattern', 'blocks.38.attn.hook_result', 'blocks.38.attn.hook_rot_k', 'blocks.38.attn.hook_rot_q', 'blocks.38.mlp.hook_pre', 'blocks.38.mlp.hook_pre_linear', 'blocks.38.mlp.hook_post', 'blocks.38.hook_attn_in', 'blocks.38.hook_q_input', 'blocks.38.hook_k_input', 'blocks.38.hook_v_input', 'blocks.38.hook_mlp_in', 'blocks.38.hook_attn_out', 'blocks.38.hook_mlp_out', 'blocks.38.hook_resid_pre', 'blocks.38.hook_resid_mid', 'blocks.38.hook_resid_post', 'blocks.39.ln1.hook_scale', 'blocks.39.ln1.hook_normalized', 'blocks.39.ln1_post.hook_scale', 'blocks.39.ln1_post.hook_normalized', 'blocks.39.ln2.hook_scale', 'blocks.39.ln2.hook_normalized', 'blocks.39.ln2_post.hook_scale', 'blocks.39.ln2_post.hook_normalized', 'blocks.39.attn.hook_k', 'blocks.39.attn.hook_q', 'blocks.39.attn.hook_v', 'blocks.39.attn.hook_z', 'blocks.39.attn.hook_attn_scores', 'blocks.39.attn.hook_pattern', 'blocks.39.attn.hook_result', 'blocks.39.attn.hook_rot_k', 'blocks.39.attn.hook_rot_q', 'blocks.39.mlp.hook_pre', 'blocks.39.mlp.hook_pre_linear', 'blocks.39.mlp.hook_post', 'blocks.39.hook_attn_in', 'blocks.39.hook_q_input', 'blocks.39.hook_k_input', 'blocks.39.hook_v_input', 'blocks.39.hook_mlp_in', 'blocks.39.hook_attn_out', 'blocks.39.hook_mlp_out', 'blocks.39.hook_resid_pre', 'blocks.39.hook_resid_mid', 'blocks.39.hook_resid_post', 'blocks.40.ln1.hook_scale', 'blocks.40.ln1.hook_normalized', 'blocks.40.ln1_post.hook_scale', 'blocks.40.ln1_post.hook_normalized', 'blocks.40.ln2.hook_scale', 'blocks.40.ln2.hook_normalized', 'blocks.40.ln2_post.hook_scale', 'blocks.40.ln2_post.hook_normalized', 'blocks.40.attn.hook_k', 'blocks.40.attn.hook_q', 'blocks.40.attn.hook_v', 'blocks.40.attn.hook_z', 'blocks.40.attn.hook_attn_scores', 'blocks.40.attn.hook_pattern', 'blocks.40.attn.hook_result', 'blocks.40.attn.hook_rot_k', 'blocks.40.attn.hook_rot_q', 'blocks.40.mlp.hook_pre', 'blocks.40.mlp.hook_pre_linear', 'blocks.40.mlp.hook_post', 'blocks.40.hook_attn_in', 'blocks.40.hook_q_input', 'blocks.40.hook_k_input', 'blocks.40.hook_v_input', 'blocks.40.hook_mlp_in', 'blocks.40.hook_attn_out', 'blocks.40.hook_mlp_out', 'blocks.40.hook_resid_pre', 'blocks.40.hook_resid_mid', 'blocks.40.hook_resid_post', 'blocks.41.ln1.hook_scale', 'blocks.41.ln1.hook_normalized', 'blocks.41.ln1_post.hook_scale', 'blocks.41.ln1_post.hook_normalized', 'blocks.41.ln2.hook_scale', 'blocks.41.ln2.hook_normalized', 'blocks.41.ln2_post.hook_scale', 'blocks.41.ln2_post.hook_normalized', 'blocks.41.attn.hook_k', 'blocks.41.attn.hook_q', 'blocks.41.attn.hook_v', 'blocks.41.attn.hook_z', 'blocks.41.attn.hook_attn_scores', 'blocks.41.attn.hook_pattern', 'blocks.41.attn.hook_result', 'blocks.41.attn.hook_rot_k', 'blocks.41.attn.hook_rot_q', 'blocks.41.mlp.hook_pre', 'blocks.41.mlp.hook_pre_linear', 'blocks.41.mlp.hook_post', 'blocks.41.hook_attn_in', 'blocks.41.hook_q_input', 'blocks.41.hook_k_input', 'blocks.41.hook_v_input', 'blocks.41.hook_mlp_in', 'blocks.41.hook_attn_out', 'blocks.41.hook_mlp_out', 'blocks.41.hook_resid_pre', 'blocks.41.hook_resid_mid', 'blocks.41.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hook_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_analyzer = AblationAnalyzer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_pairs = moral_foundations['care']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Providing shelter and food to the homeless is our fundamental duty.',\n",
       " 'Homelessness is their own problem; society has no obligation to intervene.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moral_pairs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_neurons_from_file(file_path: str) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Load list of (layer, neuron) tuples from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        neurons = json.load(f)\n",
    "    return [(int(layer), int(neuron)) for layer, neuron in neurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = load_neurons_from_file(\"../results/google-gemma-2-9b-it/2025-01-22_google-gemma-2-9b-it_fp16_moral-care_moral_neurons.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 5276),\n",
       " (8, 755),\n",
       " (11, 2295),\n",
       " (12, 1164),\n",
       " (12, 1984),\n",
       " (13, 13425),\n",
       " (14, 303),\n",
       " (14, 1718),\n",
       " (14, 2047),\n",
       " (14, 10231),\n",
       " (16, 4420),\n",
       " (16, 6638),\n",
       " (17, 10981),\n",
       " (17, 11326),\n",
       " (18, 154),\n",
       " (18, 883),\n",
       " (18, 3404),\n",
       " (19, 82),\n",
       " (19, 8658),\n",
       " (20, 9329),\n",
       " (20, 9583),\n",
       " (21, 7100),\n",
       " (22, 9482),\n",
       " (23, 86),\n",
       " (23, 128),\n",
       " (23, 4010),\n",
       " (23, 5963),\n",
       " (23, 7297),\n",
       " (23, 10673),\n",
       " (24, 476),\n",
       " (24, 2804),\n",
       " (24, 3425),\n",
       " (24, 13565),\n",
       " (25, 1203),\n",
       " (25, 9649),\n",
       " (26, 6625),\n",
       " (28, 8428),\n",
       " (28, 10813),\n",
       " (28, 12443),\n",
       " (29, 1553),\n",
       " (29, 12749),\n",
       " (31, 7661),\n",
       " (35, 9342),\n",
       " (38, 11109),\n",
       " (38, 11996),\n",
       " (39, 5546),\n",
       " (39, 13163),\n",
       " (40, 9343),\n",
       " (41, 11298)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868a435740ad473ea5d1972dc5653ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duty. It is a moral imperative to ensure that everyone has a safe place to sleep and a meal to eat.\n",
      "\n",
      "Here are some ways we can help:\n",
      "\n",
      "**Donate to local shelters and food banks:**\n",
      "\n",
      "These organizations are on the front lines, providing essential services to those in need. Your financial contributions can make a real difference in their lives.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_responses = ablation_analyzer.generate_text(moral_pairs[1][0], max_new_tokens=70, temperature=0)\n",
    "print(original_responses[len(moral_pairs[1][0]):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neurons for Moral and Ethical Princpiples\n",
    "neurons_moral_ethical_principles = [(19, 82), \n",
    "           (19, 8658),\n",
    "           (23, 5963),\n",
    "           (24, 3425),\n",
    "           (28, 10813),\n",
    "           (28, 12443),\n",
    "           ]\n",
    "\n",
    "neurons_social_structure_and_authority = [(12, 1164), \n",
    "           (16, 4420),\n",
    "           (23, 86),\n",
    "           (12, 1984),\n",
    "           (23, 10673),\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added hook to layer 16\n",
      "Added hook to layer 12\n",
      "Added hook to layer 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e540cff3c82f47868c06066f2f741518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duty.\n",
      "\n",
      "**Here's why:**\n",
      "\n",
      "* **Basic Human Rights:** Everyone deserves a safe and dignified place to live, regardless of their circumstances.\n",
      "* **Moral Imperative:**  Turning a blind eye to suffering is a moral failing. We have a responsibility to help those in need.\n",
      "* **Social Justice:** Homelessness is a symptom of\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = ablation_analyzer.ablate_neurons(\n",
    "    text=moral_pairs[1][0], \n",
    "    neurons=neurons_social_structure_and_authority,\n",
    "    ablation_value=20,\n",
    "    max_new_tokens=70,\n",
    "    temperature=0\n",
    ")\n",
    "print(result[len(moral_pairs[1][0]):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ablation_analyzer.analyze_ablation_impact(\n",
    "    moral_pairs=moral_pairs,\n",
    "    neurons=neurons,\n",
    "    ablation_value=0.0\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.mft_dim import get_moral_statements\n",
    "get_moral_statements(dimension=\"care\", moral=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
